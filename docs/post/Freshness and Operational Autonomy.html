<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://blog.meekdai.com/Gmeek/plugins/GmeekVercount.js'></script> <script type='text/javascript' src='https://udbaa.com/bnr.php?section=GeneralA&pub=847466&format=728x90&ga=g'></script> <meta name='monetag' content='a3d24bc2ef5fddc95a4ee7f54d6191b8'>
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="
Freshness is one of three components of [Materialize's Trust pillar of product value](https://materialize.com/blog/operational-attributes/#trust), the other two being responsiveness and [consistency](https://materialize.com/blog/operational-consistency/).
Operational work is fundamentally about promptly reacting to and reflecting events in the real world. 
And the real world, famously, waits for no one.
Every moment your operational layer isn't up to date represents missed opportunity as the real world moves on.

And believe it or not, staying up to date is only the tip of the operational iceberg.

Materialize uses SQL not only to query the present, but also to describe how it should respond to future events.
Your operational work shifts from being a repeated sequence of imperative SQL commands to declarative SQL views that describe your business logic.
This allows Materialize to accept responsibility for ongoing operational work, and to act autonomously where appropriate.
And it allows *you* to declaratively specify much of your operational layer, avoiding a tangle of scripts, cron jobs, and baling twine.

In this post we'll unpack how Materialize views freshness, see how it introduces autonomy at different moments, and call out the work you currently do that it can do for you instead.
We'll build up to an end-to-end demonstration borrowing from our [guided tutorial](https://materialize.com/docs/get-started/quickstart/).

## Freshness in Materialize

At the heart of freshness in Materialize is autonomous proactive work, done in response to the arrival of data rather than waiting for a user command.
User commands still exist, and Materialize promptly responds to them too, but many of the commands set up ongoing work rather than one-off work.
The proactive ongoing work spans data ingestion, view and index maintenance, and onward streaming outputs.
All of this work aims to minimize the time from data updates to their reflection in indexes (for querying) and output streams (for action).

In addition to acting proactively, we need to carefully consider the work we choose to do.
One can't simply re-do all work on each data update; we'll end up continually behind rather than at all ahead.
Ideally, we would do the *same* work as for batch processing, only performed eagerly (as the updates arrive) rather than lazily (once the batch completes).
This principle ensures that we remain throughput-competitive with batch systems, while minimizing the latency for data updates.

Let's examine the proactive work across Materialize's ingestion, computation, and output layers.

### Autonomy in Ingestion

Materialize draws input data from [sources](https://materialize.com/docs/sql/create-source/): tables maintained by external systems that Materialize should faithfully reflect.
Examples include PostgreSQL databases (through their replication log) and Kafka topics.
Materialize continually monitors these external systems, and receives data updates the first moment the systems make them available.

As Materialize receives data updates it timestamps them and commits them to its own durable storage.
The storage layer uses an append-friendly changelog format that does not need to rewrite existing data.
Log compaction happens in the background, off of the critical path and without impeding data ingestion.
Updates are available to users and their uses as soon as the timestamped data are durably committed to the OLTP database containing Materialize's storage metadata.

This ongoing work pulls data in as soon as Materialize has access to it, and attempts to do as little as possible to make it durable and then reveal it to users.
The result is continual freshness of ingested data, always as current as upstream systems have presented it.

### Autonomy in Computation

Many operational systems record data updates promptly, and then invite you to query it.
While useful, that invitation stops short of any consequent operational work that needs to be done.
If you have business logic that depends on those changed data, you'd really like to see the changes in the *outputs* rather than the *inputs*.
You'd like someone to *maintain* your business logic for you.

Materialize's maintenance of views and indexes is driven by [differential dataflow](https://github.com/TimelyDataflow/differential-dataflow), a compute engine specifically designed to minimize the end-to-end latency of data updates.
Differential dataflow provides carefully implemented data-parallel operators (e.g. `map`, `reduce`, `join`) and Materialize translates your SQL into a dataflow of these operators.
To read more about the implementation of these atomic operators, and the properties of differential dataflow generally, we recommend [the VLDB paper on Shared Arrangements](http://www.vldb.org/pvldb/vol13/p1793-mcsherry.pdf).

Even with differential dataflow, Materialize needs to carefully construct dataflows to ensure that updates happen both promptly and efficiently.
A not-uncommon pattern in other systems with shallower incremental view maintenance (IVM) support is that they fall back to expensive implementations when queries stray outside of the range of SQL the system's IVM supports.
Materialize uses the same engine to both evaluate queries and to incrementally maintain them, so it doesn't have exceptions to its IVM support.

Let's look at three examples of SQL that can be challenging to maintain in other systems: supporting updates and deletions, correlated subqueries, and recursion.

SQL aggregations `MIN` and `MAX` are not hard to maintain incrementally when you only insert data, but life gets much harder when you update or delete input data.
Your continued deletions (imagine implementing a priority queue) can eventually make any input record become the correct answer.
Materialize ensures this happens both correctly and promptly by performing aggregation in a tree, and leaving this tree structure behind as the state to maintain. 
The same construction applies equally well to maintaining views containing `ORDER BY .. LIMIT ..` clauses.

```sql
-- You can *retract* arbitrary rows from `input_tbl`,
-- and can make any input row become the correct answer.
SELECT key_col, MIN(col1), MAX(col2), ..
FROM input_tbl
GROUP BY key_col;
```
When `input_tbl` is append-only, either because its source is append-only or because this is a one-off query, Materialize is able to use the leaner implementation that keeps only the results for each `key_col`.
When `input_tbl` can change arbitrarily, Materialize prepares to minimize the update time for any changes, including retractions.

SQL has the concept of 'correlated subquery' which behave as if you you were to issue a new query for each record in some table.
Similarly, SQL's `LATERAL` join keyword allows you to manually correlate subqueries. 
For example, 
```sql
SELECT * FROM
    input_tbl,
    LATERAL (
        -- As if re-queried for each row in `input_tbl`.
        SELECT col1, col2... FROM other_tbl
        WHERE other_tbl.key_col = input_table.key_col
          AND other_tbl.val_col > input_table.val_col
        ORDER BY other_tbl.ord_col LIMIT k
    )
```
Materialize rewrites all queries to be free of subqueries in a process called decorrelation ([described here by Neumann and Kemper](https://cs.emis.de/LNI/Proceedings/Proceedings241/383.pdf)).
This way, Materialize is able to incrementally maintain arbitrary correlated subqueries.

SQL allows you to write recursive queries with `WITH RECURSIVE`.
This powerful construct is often vexxing, and we are unaware of other systems that are able to incrementally maintain anything like it for general queries.
Fortunately, differential dataflow supports recursive natively, and Materialize supports incremental evaluation and maintenance through its (slightly different) [`WITH MUTUALLY RECURSIVE`](https://materialize.com/docs/sql/recursive-ctes/#details) construct.

Not all of Materialize's dataflows are flawless.
Window functions in particular are challenging to support in their full generality, as they allow rich computation and aren't as easily eliminated as are correlated subqueries.
However they, like any other limitations, are being actively pursued and should only improve!

Although there is a lot to know here, Materialize's computation layer is continually working to maintain your SQL views and indexes as the underlying data change.
This is all in pursuit of freshness, pushing data updates through business logic proactively, both to be ready with fresh indexed results and to communicate them onward.

### Autonomy in Query Serving

The most common mode of interaction with a SQL system, the `SELECT` query, isn't great from the perspective of freshness.
You are required to repeatedly ask the system for results, and when there is a change you need to be the one to notice it.

Materialize adds a new command, [`SUBSCRIBE`](https://materialize.com/docs/sql/subscribe/), which like `SELECT` gives you the answer to your query, but then continues with a stream of timestamped updates that tell you about changes to those results as soon as they happen.
The `SUBSCRIBE` command allows you to build fresh applications without continually hammering the systems with polling `SELECT` statements.

Materialize also has the concept of a [SINK](https://materialize.com/docs/sql/create-sink/), which is roughly the output complement to an input `SOURCE`: it pushes the information of a `SUBSCRIBE` on to an external system, such as a Kafka topic.
Downstream systems can listen to these sinks to see updates to maintained views as soon as they happen.

Let's see `SUBSCRIBE` in action, using an example from our [guided tutorial](https://materialize.com/docs/get-started/quickstart/). 
Specifically, we'll head to ['Step 3: See results change!'](https://materialize.com/docs/get-started/quickstart/#step-3-see-results-change), in case you'd like to follow along.
In this example we have a large, continually changing view `winning_bids` of auction winners, some of which may correspond to fraudulent accounts.
We introduce a new table on the side, `fraud_accounts`, and want to monitor the top non-fraudent auction winners, written
```sql
SUBSCRIBE TO (
  SELECT buyer, count(*)
  FROM winning_bids
  WHERE buyer NOT IN (SELECT id FROM fraud_accounts)
  GROUP BY buyer
  ORDER BY 2 DESC LIMIT 5
);
```
We can look at the output and take any of the top buyers and (perhaps unfairly) flag them as fraudulent by inserting them into `fraud_accounts`.
 Perhaps we investigate and clear them, then deleting them from `fraud_accounts`. 
 Each action results in an immediate update to the `SUBSCRIBE` output.
The example demonstrates each of the layers, ingesting updates promptly from both tables and sources, moving the updates through an `ORDER BY .. LIMIT` dataflow with a (non-correlated) subquery, and surfacing output updates as soon as they occur.

The `SUBSCRIBE` and `SINK` constructs allow Materialize to serve fresh results as soon as they happen.
Users and applications are not required to anticipate changes, nor poll the system on a tight cadence.

## Freshness and Operational Autonomy

An operational layer wants to be able to connect the dots from input updates and events, through business logic, on to downstream systems that can take the appropriate actions.
To achieve this one must build autonomy into each of the layers of ingestion, computation, and serving.
If any of these layers aren't fully autonomous, you or code acting on your behalf will have to poke them into action on some regular basis.
You'll also likely be responsible for interpreting the results and determining if they merit propagating onward.

Materialize specifically allow you to install operational business logic that keeps its results up to date and allows others to take action the moment results change.
It does this by making its internal components update autonomously and proactively, as updates to data occur.
Materialize can absorb end-to-end responsibility for this operational work, framed as SQL views.

If freshness and operational autonomy sound exciting to you, we invite you to try out Materialize for yourself.
Our [guided tutorial](https://www.materialize.com/docs/get-started/quickstart/) builds up the auction data sources described above, and includes demonstrations of consistency.
If you'd like to try out Materialize on larger volumes of your own data, reach out about doing a [Proof of Concept](https://materialize.com/trial/) with us!

<!-- ##{'timestamp':1695963600}## -->。">
<meta property="og:title" content="Freshness and Operational Autonomy">
<meta property="og:description" content="
Freshness is one of three components of [Materialize's Trust pillar of product value](https://materialize.com/blog/operational-attributes/#trust), the other two being responsiveness and [consistency](https://materialize.com/blog/operational-consistency/).
Operational work is fundamentally about promptly reacting to and reflecting events in the real world. 
And the real world, famously, waits for no one.
Every moment your operational layer isn't up to date represents missed opportunity as the real world moves on.

And believe it or not, staying up to date is only the tip of the operational iceberg.

Materialize uses SQL not only to query the present, but also to describe how it should respond to future events.
Your operational work shifts from being a repeated sequence of imperative SQL commands to declarative SQL views that describe your business logic.
This allows Materialize to accept responsibility for ongoing operational work, and to act autonomously where appropriate.
And it allows *you* to declaratively specify much of your operational layer, avoiding a tangle of scripts, cron jobs, and baling twine.

In this post we'll unpack how Materialize views freshness, see how it introduces autonomy at different moments, and call out the work you currently do that it can do for you instead.
We'll build up to an end-to-end demonstration borrowing from our [guided tutorial](https://materialize.com/docs/get-started/quickstart/).

## Freshness in Materialize

At the heart of freshness in Materialize is autonomous proactive work, done in response to the arrival of data rather than waiting for a user command.
User commands still exist, and Materialize promptly responds to them too, but many of the commands set up ongoing work rather than one-off work.
The proactive ongoing work spans data ingestion, view and index maintenance, and onward streaming outputs.
All of this work aims to minimize the time from data updates to their reflection in indexes (for querying) and output streams (for action).

In addition to acting proactively, we need to carefully consider the work we choose to do.
One can't simply re-do all work on each data update; we'll end up continually behind rather than at all ahead.
Ideally, we would do the *same* work as for batch processing, only performed eagerly (as the updates arrive) rather than lazily (once the batch completes).
This principle ensures that we remain throughput-competitive with batch systems, while minimizing the latency for data updates.

Let's examine the proactive work across Materialize's ingestion, computation, and output layers.

### Autonomy in Ingestion

Materialize draws input data from [sources](https://materialize.com/docs/sql/create-source/): tables maintained by external systems that Materialize should faithfully reflect.
Examples include PostgreSQL databases (through their replication log) and Kafka topics.
Materialize continually monitors these external systems, and receives data updates the first moment the systems make them available.

As Materialize receives data updates it timestamps them and commits them to its own durable storage.
The storage layer uses an append-friendly changelog format that does not need to rewrite existing data.
Log compaction happens in the background, off of the critical path and without impeding data ingestion.
Updates are available to users and their uses as soon as the timestamped data are durably committed to the OLTP database containing Materialize's storage metadata.

This ongoing work pulls data in as soon as Materialize has access to it, and attempts to do as little as possible to make it durable and then reveal it to users.
The result is continual freshness of ingested data, always as current as upstream systems have presented it.

### Autonomy in Computation

Many operational systems record data updates promptly, and then invite you to query it.
While useful, that invitation stops short of any consequent operational work that needs to be done.
If you have business logic that depends on those changed data, you'd really like to see the changes in the *outputs* rather than the *inputs*.
You'd like someone to *maintain* your business logic for you.

Materialize's maintenance of views and indexes is driven by [differential dataflow](https://github.com/TimelyDataflow/differential-dataflow), a compute engine specifically designed to minimize the end-to-end latency of data updates.
Differential dataflow provides carefully implemented data-parallel operators (e.g. `map`, `reduce`, `join`) and Materialize translates your SQL into a dataflow of these operators.
To read more about the implementation of these atomic operators, and the properties of differential dataflow generally, we recommend [the VLDB paper on Shared Arrangements](http://www.vldb.org/pvldb/vol13/p1793-mcsherry.pdf).

Even with differential dataflow, Materialize needs to carefully construct dataflows to ensure that updates happen both promptly and efficiently.
A not-uncommon pattern in other systems with shallower incremental view maintenance (IVM) support is that they fall back to expensive implementations when queries stray outside of the range of SQL the system's IVM supports.
Materialize uses the same engine to both evaluate queries and to incrementally maintain them, so it doesn't have exceptions to its IVM support.

Let's look at three examples of SQL that can be challenging to maintain in other systems: supporting updates and deletions, correlated subqueries, and recursion.

SQL aggregations `MIN` and `MAX` are not hard to maintain incrementally when you only insert data, but life gets much harder when you update or delete input data.
Your continued deletions (imagine implementing a priority queue) can eventually make any input record become the correct answer.
Materialize ensures this happens both correctly and promptly by performing aggregation in a tree, and leaving this tree structure behind as the state to maintain. 
The same construction applies equally well to maintaining views containing `ORDER BY .. LIMIT ..` clauses.

```sql
-- You can *retract* arbitrary rows from `input_tbl`,
-- and can make any input row become the correct answer.
SELECT key_col, MIN(col1), MAX(col2), ..
FROM input_tbl
GROUP BY key_col;
```
When `input_tbl` is append-only, either because its source is append-only or because this is a one-off query, Materialize is able to use the leaner implementation that keeps only the results for each `key_col`.
When `input_tbl` can change arbitrarily, Materialize prepares to minimize the update time for any changes, including retractions.

SQL has the concept of 'correlated subquery' which behave as if you you were to issue a new query for each record in some table.
Similarly, SQL's `LATERAL` join keyword allows you to manually correlate subqueries. 
For example, 
```sql
SELECT * FROM
    input_tbl,
    LATERAL (
        -- As if re-queried for each row in `input_tbl`.
        SELECT col1, col2... FROM other_tbl
        WHERE other_tbl.key_col = input_table.key_col
          AND other_tbl.val_col > input_table.val_col
        ORDER BY other_tbl.ord_col LIMIT k
    )
```
Materialize rewrites all queries to be free of subqueries in a process called decorrelation ([described here by Neumann and Kemper](https://cs.emis.de/LNI/Proceedings/Proceedings241/383.pdf)).
This way, Materialize is able to incrementally maintain arbitrary correlated subqueries.

SQL allows you to write recursive queries with `WITH RECURSIVE`.
This powerful construct is often vexxing, and we are unaware of other systems that are able to incrementally maintain anything like it for general queries.
Fortunately, differential dataflow supports recursive natively, and Materialize supports incremental evaluation and maintenance through its (slightly different) [`WITH MUTUALLY RECURSIVE`](https://materialize.com/docs/sql/recursive-ctes/#details) construct.

Not all of Materialize's dataflows are flawless.
Window functions in particular are challenging to support in their full generality, as they allow rich computation and aren't as easily eliminated as are correlated subqueries.
However they, like any other limitations, are being actively pursued and should only improve!

Although there is a lot to know here, Materialize's computation layer is continually working to maintain your SQL views and indexes as the underlying data change.
This is all in pursuit of freshness, pushing data updates through business logic proactively, both to be ready with fresh indexed results and to communicate them onward.

### Autonomy in Query Serving

The most common mode of interaction with a SQL system, the `SELECT` query, isn't great from the perspective of freshness.
You are required to repeatedly ask the system for results, and when there is a change you need to be the one to notice it.

Materialize adds a new command, [`SUBSCRIBE`](https://materialize.com/docs/sql/subscribe/), which like `SELECT` gives you the answer to your query, but then continues with a stream of timestamped updates that tell you about changes to those results as soon as they happen.
The `SUBSCRIBE` command allows you to build fresh applications without continually hammering the systems with polling `SELECT` statements.

Materialize also has the concept of a [SINK](https://materialize.com/docs/sql/create-sink/), which is roughly the output complement to an input `SOURCE`: it pushes the information of a `SUBSCRIBE` on to an external system, such as a Kafka topic.
Downstream systems can listen to these sinks to see updates to maintained views as soon as they happen.

Let's see `SUBSCRIBE` in action, using an example from our [guided tutorial](https://materialize.com/docs/get-started/quickstart/). 
Specifically, we'll head to ['Step 3: See results change!'](https://materialize.com/docs/get-started/quickstart/#step-3-see-results-change), in case you'd like to follow along.
In this example we have a large, continually changing view `winning_bids` of auction winners, some of which may correspond to fraudulent accounts.
We introduce a new table on the side, `fraud_accounts`, and want to monitor the top non-fraudent auction winners, written
```sql
SUBSCRIBE TO (
  SELECT buyer, count(*)
  FROM winning_bids
  WHERE buyer NOT IN (SELECT id FROM fraud_accounts)
  GROUP BY buyer
  ORDER BY 2 DESC LIMIT 5
);
```
We can look at the output and take any of the top buyers and (perhaps unfairly) flag them as fraudulent by inserting them into `fraud_accounts`.
 Perhaps we investigate and clear them, then deleting them from `fraud_accounts`. 
 Each action results in an immediate update to the `SUBSCRIBE` output.
The example demonstrates each of the layers, ingesting updates promptly from both tables and sources, moving the updates through an `ORDER BY .. LIMIT` dataflow with a (non-correlated) subquery, and surfacing output updates as soon as they occur.

The `SUBSCRIBE` and `SINK` constructs allow Materialize to serve fresh results as soon as they happen.
Users and applications are not required to anticipate changes, nor poll the system on a tight cadence.

## Freshness and Operational Autonomy

An operational layer wants to be able to connect the dots from input updates and events, through business logic, on to downstream systems that can take the appropriate actions.
To achieve this one must build autonomy into each of the layers of ingestion, computation, and serving.
If any of these layers aren't fully autonomous, you or code acting on your behalf will have to poke them into action on some regular basis.
You'll also likely be responsible for interpreting the results and determining if they merit propagating onward.

Materialize specifically allow you to install operational business logic that keeps its results up to date and allows others to take action the moment results change.
It does this by making its internal components update autonomously and proactively, as updates to data occur.
Materialize can absorb end-to-end responsibility for this operational work, framed as SQL views.

If freshness and operational autonomy sound exciting to you, we invite you to try out Materialize for yourself.
Our [guided tutorial](https://www.materialize.com/docs/get-started/quickstart/) builds up the auction data sources described above, and includes demonstrations of consistency.
If you'd like to try out Materialize on larger volumes of your own data, reach out about doing a [Proof of Concept](https://materialize.com/trial/) with us!

<!-- ##{'timestamp':1695963600}## -->。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://nuowoo.github.io/blog/post/Freshness%20and%20Operational%20Autonomy.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>Freshness and Operational Autonomy</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">Freshness and Operational Autonomy</h1>
<div class="title-right">
    <a href="https://nuowoo.github.io/blog" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/nuowoo/blog/issues/8" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><p>Freshness is one of three components of <a href="https://materialize.com/blog/operational-attributes/#trust" rel="nofollow">Materialize's Trust pillar of product value</a>, the other two being responsiveness and <a href="https://materialize.com/blog/operational-consistency/" rel="nofollow">consistency</a>.<br>
Operational work is fundamentally about promptly reacting to and reflecting events in the real world.<br>
And the real world, famously, waits for no one.<br>
Every moment your operational layer isn't up to date represents missed opportunity as the real world moves on.</p>
<p>And believe it or not, staying up to date is only the tip of the operational iceberg.</p>
<p>Materialize uses SQL not only to query the present, but also to describe how it should respond to future events.<br>
Your operational work shifts from being a repeated sequence of imperative SQL commands to declarative SQL views that describe your business logic.<br>
This allows Materialize to accept responsibility for ongoing operational work, and to act autonomously where appropriate.<br>
And it allows <em>you</em> to declaratively specify much of your operational layer, avoiding a tangle of scripts, cron jobs, and baling twine.</p>
<p>In this post we'll unpack how Materialize views freshness, see how it introduces autonomy at different moments, and call out the work you currently do that it can do for you instead.<br>
We'll build up to an end-to-end demonstration borrowing from our <a href="https://materialize.com/docs/get-started/quickstart/" rel="nofollow">guided tutorial</a>.</p>
<h2>Freshness in Materialize</h2>
<p>At the heart of freshness in Materialize is autonomous proactive work, done in response to the arrival of data rather than waiting for a user command.<br>
User commands still exist, and Materialize promptly responds to them too, but many of the commands set up ongoing work rather than one-off work.<br>
The proactive ongoing work spans data ingestion, view and index maintenance, and onward streaming outputs.<br>
All of this work aims to minimize the time from data updates to their reflection in indexes (for querying) and output streams (for action).</p>
<p>In addition to acting proactively, we need to carefully consider the work we choose to do.<br>
One can't simply re-do all work on each data update; we'll end up continually behind rather than at all ahead.<br>
Ideally, we would do the <em>same</em> work as for batch processing, only performed eagerly (as the updates arrive) rather than lazily (once the batch completes).<br>
This principle ensures that we remain throughput-competitive with batch systems, while minimizing the latency for data updates.</p>
<p>Let's examine the proactive work across Materialize's ingestion, computation, and output layers.</p>
<h3>Autonomy in Ingestion</h3>
<p>Materialize draws input data from <a href="https://materialize.com/docs/sql/create-source/" rel="nofollow">sources</a>: tables maintained by external systems that Materialize should faithfully reflect.<br>
Examples include PostgreSQL databases (through their replication log) and Kafka topics.<br>
Materialize continually monitors these external systems, and receives data updates the first moment the systems make them available.</p>
<p>As Materialize receives data updates it timestamps them and commits them to its own durable storage.<br>
The storage layer uses an append-friendly changelog format that does not need to rewrite existing data.<br>
Log compaction happens in the background, off of the critical path and without impeding data ingestion.<br>
Updates are available to users and their uses as soon as the timestamped data are durably committed to the OLTP database containing Materialize's storage metadata.</p>
<p>This ongoing work pulls data in as soon as Materialize has access to it, and attempts to do as little as possible to make it durable and then reveal it to users.<br>
The result is continual freshness of ingested data, always as current as upstream systems have presented it.</p>
<h3>Autonomy in Computation</h3>
<p>Many operational systems record data updates promptly, and then invite you to query it.<br>
While useful, that invitation stops short of any consequent operational work that needs to be done.<br>
If you have business logic that depends on those changed data, you'd really like to see the changes in the <em>outputs</em> rather than the <em>inputs</em>.<br>
You'd like someone to <em>maintain</em> your business logic for you.</p>
<p>Materialize's maintenance of views and indexes is driven by <a href="https://github.com/TimelyDataflow/differential-dataflow">differential dataflow</a>, a compute engine specifically designed to minimize the end-to-end latency of data updates.<br>
Differential dataflow provides carefully implemented data-parallel operators (e.g. <code class="notranslate">map</code>, <code class="notranslate">reduce</code>, <code class="notranslate">join</code>) and Materialize translates your SQL into a dataflow of these operators.<br>
To read more about the implementation of these atomic operators, and the properties of differential dataflow generally, we recommend <a href="http://www.vldb.org/pvldb/vol13/p1793-mcsherry.pdf" rel="nofollow">the VLDB paper on Shared Arrangements</a>.</p>
<p>Even with differential dataflow, Materialize needs to carefully construct dataflows to ensure that updates happen both promptly and efficiently.<br>
A not-uncommon pattern in other systems with shallower incremental view maintenance (IVM) support is that they fall back to expensive implementations when queries stray outside of the range of SQL the system's IVM supports.<br>
Materialize uses the same engine to both evaluate queries and to incrementally maintain them, so it doesn't have exceptions to its IVM support.</p>
<p>Let's look at three examples of SQL that can be challenging to maintain in other systems: supporting updates and deletions, correlated subqueries, and recursion.</p>
<p>SQL aggregations <code class="notranslate">MIN</code> and <code class="notranslate">MAX</code> are not hard to maintain incrementally when you only insert data, but life gets much harder when you update or delete input data.<br>
Your continued deletions (imagine implementing a priority queue) can eventually make any input record become the correct answer.<br>
Materialize ensures this happens both correctly and promptly by performing aggregation in a tree, and leaving this tree structure behind as the state to maintain.<br>
The same construction applies equally well to maintaining views containing <code class="notranslate">ORDER BY .. LIMIT ..</code> clauses.</p>
<div class="highlight highlight-source-sql"><pre class="notranslate"><span class="pl-c"><span class="pl-c">--</span> You can *retract* arbitrary rows from `input_tbl`,</span>
<span class="pl-c"><span class="pl-c">--</span> and can make any input row become the correct answer.</span>
<span class="pl-k">SELECT</span> key_col, <span class="pl-c1">MIN</span>(col1), <span class="pl-c1">MAX</span>(col2), ..
<span class="pl-k">FROM</span> input_tbl
<span class="pl-k">GROUP BY</span> key_col;</pre></div>
<p>When <code class="notranslate">input_tbl</code> is append-only, either because its source is append-only or because this is a one-off query, Materialize is able to use the leaner implementation that keeps only the results for each <code class="notranslate">key_col</code>.<br>
When <code class="notranslate">input_tbl</code> can change arbitrarily, Materialize prepares to minimize the update time for any changes, including retractions.</p>
<p>SQL has the concept of "correlated subquery" which behave as if you you were to issue a new query for each record in some table.<br>
Similarly, SQL's <code class="notranslate">LATERAL</code> join keyword allows you to manually correlate subqueries.<br>
For example,</p>
<div class="highlight highlight-source-sql"><pre class="notranslate"><span class="pl-k">SELECT</span> <span class="pl-k">*</span> <span class="pl-k">FROM</span>
    input_tbl,
    LATERAL (
        <span class="pl-c"><span class="pl-c">--</span> As if re-queried for each row in `input_tbl`.</span>
        <span class="pl-k">SELECT</span> col1, col2... <span class="pl-k">FROM</span> other_tbl
        <span class="pl-k">WHERE</span> <span class="pl-c1">other_tbl</span>.<span class="pl-c1">key_col</span> <span class="pl-k">=</span> <span class="pl-c1">input_table</span>.<span class="pl-c1">key_col</span>
          <span class="pl-k">AND</span> <span class="pl-c1">other_tbl</span>.<span class="pl-c1">val_col</span> <span class="pl-k">&gt;</span> <span class="pl-c1">input_table</span>.<span class="pl-c1">val_col</span>
        <span class="pl-k">ORDER BY</span> <span class="pl-c1">other_tbl</span>.<span class="pl-c1">ord_col</span> <span class="pl-k">LIMIT</span> k
    )</pre></div>
<p>Materialize rewrites all queries to be free of subqueries in a process called decorrelation (<a href="https://cs.emis.de/LNI/Proceedings/Proceedings241/383.pdf" rel="nofollow">described here by Neumann and Kemper</a>).<br>
This way, Materialize is able to incrementally maintain arbitrary correlated subqueries.</p>
<p>SQL allows you to write recursive queries with <code class="notranslate">WITH RECURSIVE</code>.<br>
This powerful construct is often vexxing, and we are unaware of other systems that are able to incrementally maintain anything like it for general queries.<br>
Fortunately, differential dataflow supports recursive natively, and Materialize supports incremental evaluation and maintenance through its (slightly different) <a href="https://materialize.com/docs/sql/recursive-ctes/#details" rel="nofollow"><code class="notranslate">WITH MUTUALLY RECURSIVE</code></a> construct.</p>
<p>Not all of Materialize's dataflows are flawless.<br>
Window functions in particular are challenging to support in their full generality, as they allow rich computation and aren't as easily eliminated as are correlated subqueries.<br>
However they, like any other limitations, are being actively pursued and should only improve!</p>
<p>Although there is a lot to know here, Materialize's computation layer is continually working to maintain your SQL views and indexes as the underlying data change.<br>
This is all in pursuit of freshness, pushing data updates through business logic proactively, both to be ready with fresh indexed results and to communicate them onward.</p>
<h3>Autonomy in Query Serving</h3>
<p>The most common mode of interaction with a SQL system, the <code class="notranslate">SELECT</code> query, isn't great from the perspective of freshness.<br>
You are required to repeatedly ask the system for results, and when there is a change you need to be the one to notice it.</p>
<p>Materialize adds a new command, <a href="https://materialize.com/docs/sql/subscribe/" rel="nofollow"><code class="notranslate">SUBSCRIBE</code></a>, which like <code class="notranslate">SELECT</code> gives you the answer to your query, but then continues with a stream of timestamped updates that tell you about changes to those results as soon as they happen.<br>
The <code class="notranslate">SUBSCRIBE</code> command allows you to build fresh applications without continually hammering the systems with polling <code class="notranslate">SELECT</code> statements.</p>
<p>Materialize also has the concept of a <a href="https://materialize.com/docs/sql/create-sink/" rel="nofollow">SINK</a>, which is roughly the output complement to an input <code class="notranslate">SOURCE</code>: it pushes the information of a <code class="notranslate">SUBSCRIBE</code> on to an external system, such as a Kafka topic.<br>
Downstream systems can listen to these sinks to see updates to maintained views as soon as they happen.</p>
<p>Let's see <code class="notranslate">SUBSCRIBE</code> in action, using an example from our <a href="https://materialize.com/docs/get-started/quickstart/" rel="nofollow">guided tutorial</a>.<br>
Specifically, we'll head to <a href="https://materialize.com/docs/get-started/quickstart/#step-3-see-results-change" rel="nofollow">"Step 3: See results change!"</a>, in case you'd like to follow along.<br>
In this example we have a large, continually changing view <code class="notranslate">winning_bids</code> of auction winners, some of which may correspond to fraudulent accounts.<br>
We introduce a new table on the side, <code class="notranslate">fraud_accounts</code>, and want to monitor the top non-fraudent auction winners, written</p>
<div class="highlight highlight-source-sql"><pre class="notranslate">SUBSCRIBE TO (
  <span class="pl-k">SELECT</span> buyer, <span class="pl-c1">count</span>(<span class="pl-k">*</span>)
  <span class="pl-k">FROM</span> winning_bids
  <span class="pl-k">WHERE</span> buyer NOT <span class="pl-k">IN</span> (<span class="pl-k">SELECT</span> id <span class="pl-k">FROM</span> fraud_accounts)
  <span class="pl-k">GROUP BY</span> buyer
  <span class="pl-k">ORDER BY</span> <span class="pl-c1">2</span> <span class="pl-k">DESC</span> <span class="pl-k">LIMIT</span> <span class="pl-c1">5</span>
);</pre></div>
<p>We can look at the output and take any of the top buyers and (perhaps unfairly) flag them as fraudulent by inserting them into <code class="notranslate">fraud_accounts</code>.<br>
Perhaps we investigate and clear them, then deleting them from <code class="notranslate">fraud_accounts</code>.<br>
Each action results in an immediate update to the <code class="notranslate">SUBSCRIBE</code> output.<br>
The example demonstrates each of the layers, ingesting updates promptly from both tables and sources, moving the updates through an <code class="notranslate">ORDER BY .. LIMIT</code> dataflow with a (non-correlated) subquery, and surfacing output updates as soon as they occur.</p>
<p>The <code class="notranslate">SUBSCRIBE</code> and <code class="notranslate">SINK</code> constructs allow Materialize to serve fresh results as soon as they happen.<br>
Users and applications are not required to anticipate changes, nor poll the system on a tight cadence.</p>
<h2>Freshness and Operational Autonomy</h2>
<p>An operational layer wants to be able to connect the dots from input updates and events, through business logic, on to downstream systems that can take the appropriate actions.<br>
To achieve this one must build autonomy into each of the layers of ingestion, computation, and serving.<br>
If any of these layers aren't fully autonomous, you or code acting on your behalf will have to poke them into action on some regular basis.<br>
You'll also likely be responsible for interpreting the results and determining if they merit propagating onward.</p>
<p>Materialize specifically allow you to install operational business logic that keeps its results up to date and allows others to take action the moment results change.<br>
It does this by making its internal components update autonomously and proactively, as updates to data occur.<br>
Materialize can absorb end-to-end responsibility for this operational work, framed as SQL views.</p>
<p>If freshness and operational autonomy sound exciting to you, we invite you to try out Materialize for yourself.<br>
Our <a href="https://www.materialize.com/docs/get-started/quickstart/" rel="nofollow">guided tutorial</a> builds up the auction data sources described above, and includes demonstrations of consistency.<br>
If you'd like to try out Materialize on larger volumes of your own data, reach out about doing a <a href="https://materialize.com/trial/" rel="nofollow">Proof of Concept</a> with us!</p>
</div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://nuowoo.github.io/blog">Computer Scientist</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","nuowoo/blog");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>


</html>
